{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Copia1 de Tarea - Transformers for Sentiment Analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edcalderin/DeepLearning_SaturdaysAI/blob/master/Tareas/Tarea_Transformers_for_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6KZuoDX5rMD"
      },
      "source": [
        "# Tarea: Advanced Topics\n",
        "### Grupo: XXXXX\n",
        "Integrantes:\n",
        "<br>\n",
        "* Integrante 1 \n",
        "* Integrante 2\n",
        "* Integrante 3\n",
        "* Integrante 4\n",
        "<br>\n",
        "\n",
        "Indicaciones:\n",
        "<rb>\n",
        "* Debe realizar la siguiente tarea hasta el domingo 27 de junio, 23:59 UTC - 4\n",
        "* Debe hacer una copia de este notebook para poder editar el código.\n",
        "* Una vez finalizado el trabajo debe subir el link de su notebook (con permisos de lector) en la sección de \"Tareas\" del Módulo 5: Advanced Topics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHoAaFaB8E3s"
      },
      "source": [
        "# Transformers para análisis de sentimiento\n",
        "\n",
        "En la clase práctica de Transformers se definió una clase para tratamiento de problemas Seq2Seq y también se analizó como usar los transformers para la clasificación. En el ejercicio de esta tarea utilizarán la clase Seq2SeqTransformer para la clasificación.\n",
        "\n",
        "Para ellos utilizaremos los datos de IMDB, de comentarios de películas en inglés y los clasificaremos en positivos o negativos.\n",
        "\n",
        "Para más detalles de este problema y otras formas de resolverlos vea: [análisis de sentimiento con pytorch en github](https://github.com/bentrevett/pytorch-sentiment-analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwhPlikqtv34"
      },
      "source": [
        "## Ejercicio: \n",
        "\n",
        "Crea una clase Seq2ClassTransformer a partir de  Seq2SeqTransformer que pueda ser utilizada para la clasificación. Utiliza una de las dos variantes mencionadas en clase:\n",
        "\n",
        "1.   Adiciona el clasificador al final del codificador mediante el uso de una capa MLP.\n",
        "2.   Adiciona el token de clasificación como parte de la secuencia, como el ejemplo visto en clase de la clasificación de imágenes.\n",
        "\n",
        "Haz los cambios necesarios para que el código funcione. Entrena el modelo utilizando varios valores para los hiperparámetros:\n",
        "\n",
        "* EMB_SIZE = {256, 512}\n",
        "* NHEAD = {4, 8}\n",
        "* NUM_ENCODER_LAYERS = {2, 3}\n",
        "\n",
        "\n",
        "Presenta los gráficos en tiempo de entrenamiento, de la precisión y pérdida (accuracy y loss) en el conjunto de validación y de entrenamiento, para cada una de las épocas.\n",
        "Presenta los datos de testing en una tabla para cada una de las combinaciones\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sQW1wdUxqXP"
      },
      "source": [
        "La entrega de la tarea será el notebook con el código y los gráficos. Por favor utilicen la misma semilla (SEED) para ejecutar su código para garantizar reproducibilidad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcT-YccD8E3u"
      },
      "source": [
        "import torch\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV8dXyV88cN6"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0AFvdXC8E3x"
      },
      "source": [
        "init_token = tokenizer.cls_token\n",
        "eos_token = tokenizer.sep_token\n",
        "pad_token = tokenizer.pad_token\n",
        "unk_token = tokenizer.unk_token\n",
        "\n",
        "print(init_token, eos_token, pad_token, unk_token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EueGIQos8E3y"
      },
      "source": [
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3evv901F8E30"
      },
      "source": [
        "from torchtext.legacy import data\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm')\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4S60rpi8E31"
      },
      "source": [
        "from torchtext.legacy import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41FvMSVcjUH8"
      },
      "source": [
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeKNd6Yf8E32"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY5pAJey8E33"
      },
      "source": [
        "## Construcción del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xkDWxULfcdT"
      },
      "source": [
        "import math\n",
        "import torchtext\n",
        "import torch.nn as nn\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import Vocab\n",
        "from torch import Tensor\n",
        "import io\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QMIJAwJfZCN"
      },
      "source": [
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "        \n",
        "    def forward(self, tokens: Tensor):\n",
        "        embedding = self.embedding(tokens.long())\n",
        "        return embedding * math.sqrt(self.emb_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnWvVV5vfSez"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, emb_size: int, dropout, maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        pos_embedding = self.pos_embedding[:token_embedding.size(0),:]\n",
        "        embedding = token_embedding + pos_embedding\n",
        "        return self.dropout(embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr8XWSF9euHY"
      },
      "source": [
        "def create_mask(src):\n",
        "  src_seq_len = src.shape[0]\n",
        "  src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
        "\n",
        "  src_padding_mask = (src == pad_token_idx).transpose(0, 1)\n",
        "  return src_mask, src_padding_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXYHji4Seqay"
      },
      "source": [
        "# Crea la clase Seq2ClassTransformer Aquí, tomando como ejemplo la clase Seq2SeqTransformer vista en clase"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJcpIOME8E34"
      },
      "source": [
        "SRC_VOCAB_SIZE = len(tokenizer.vocab)\n",
        "EMB_SIZE = 256\n",
        "NHEAD = 4\n",
        "FFN_HID_DIM = 256\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "transformer = # Completa el código del modelo\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(device)\n",
        "\n",
        "loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9\n",
        ")\n",
        "\n",
        "loss = loss.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WEz13FZ8E37"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhwsrG7Zfp7i"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Crea la máscara\n",
        "        predictions = # Completa la llamada al modelo\n",
        "        \n",
        "\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ0NjaCf8E37"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            # Crea la máscara\n",
        "            predictions = # Completa la llamada al modelo\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9To2t0q8E38"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8-Z3Au98E38"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(transformer, train_iterator, optimizer, loss)\n",
        "    valid_loss, valid_acc = evaluate(transformer, valid_iterator, loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'transformer.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-4x3C6K8E39"
      },
      "source": [
        "model.load_state_dict(torch.load('transformer.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFfmQjdy8E39"
      },
      "source": [
        "## Inferencia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am1spb1u8E39"
      },
      "source": [
        "def predict_sentiment(model, tokenizer, sentence):\n",
        "    model.eval()\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "    prediction = torch.sigmoid(model(tensor))\n",
        "    return prediction.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgpEskIJ8E39"
      },
      "source": [
        "predict_sentiment(transformer, tokenizer, \"This film is terrible\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaJ4Dnac8E39"
      },
      "source": [
        "predict_sentiment(transformer, tokenizer, \"This film is great\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}