{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN Tarea.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edcalderin/DeepLearning_SaturdaysAI/blob/master/Tareas/Tarea_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vIUO240ZrDd"
      },
      "source": [
        "# Tarea: GAN\n",
        "### Grupo: XXXXX\n",
        "Integrantes:\n",
        "<br>\n",
        "* Integrante 1 \n",
        "* Integrante 2\n",
        "* Integrante 3\n",
        "* Integrante 4\n",
        "<br>\n",
        "\n",
        "Indicaciones:\n",
        "<rb>\n",
        "* Debe realizar la siguiente tarea hasta el 04 de julio, 23:59 UTC - 4\n",
        "* Debe hacer una copia de este notebook para poder editar el código.\n",
        "* Una vez finalizado el trabajo debe subir el link de su notebook (con permisos de lector) en la sección de \"Tareas\" del módulo correspondiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rku_fDQAbzOu"
      },
      "source": [
        "Para la tarea se puede elegir una de tres opciones:\n",
        "\n",
        "\n",
        "A) Partiendo de la red GAN vista en clase tomar otro dataset y entrenar para él. Por ejemplo se puede usar el dataset: https://ai.stanford.edu/~jkrause/cars/car_dataset.html\n",
        "\n",
        "B) Partiendo de la red GAN vista en clase, utilizando MNIST, trabajar con la red DCGAN: https://arxiv.org/pdf/1511.06434.pdf\n",
        "\n",
        "C) Realizar A y B al mismo tiempo\n",
        "\n",
        "\n",
        "Se deja a modo de ejemplo parte del código de un posible discriminador para la opción B) a continuación y código auxiliar para obtener el dataset de A).\n",
        "\n",
        "Se recomienda si se realizan entrenamientos muy largos ejecutar el código en una instancia cloud, no en Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxhN9WEqnAHB"
      },
      "source": [
        "from torchvision.datasets.utils import download_url\n",
        "import tarfile\n",
        "dataset_url = 'https://s3.amazonaws.com/fast-ai-imageclas/stanford-cars.tgz'\n",
        "download_url(dataset_url, '.')\n",
        "with tarfile.open('./stanford-cars.tgz', 'r:gz' )as tar:\n",
        "                  tar.extractall(path= './cars_data')\n",
        "data_dir = './cars_data/stanford-cars'\n",
        "train_dir = data_dir +'/cars_train'\n",
        "print(os.listdir(data_dir))\n",
        "len(train_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QYShK5_deOh"
      },
      "source": [
        "IMAGE_DIM = (32, 32, 3)\n",
        "def get_sample_image(G, n_noise):\n",
        "    \"\"\"\n",
        "        save sample 100 images\n",
        "    \"\"\"\n",
        "    z = torch.randn(10, n_noise).to(DEVICE)\n",
        "    y_hat = G(z).view(10, 3, 32, 32).permute(0, 2, 3, 1) # (100, 28, 28)\n",
        "    result = (y_hat.detach().cpu().numpy()+1)/2.\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJvfN-OUbyrI"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channel=1, num_classes=1):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            # Reduce size\n",
        "            nn.Conv2d(in_channel, 512, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # Reduce size\n",
        "            # @TODO\n",
        "\n",
        "            # Reduce size\n",
        "            # @TODO\n",
        "            \n",
        "            # \n",
        "            nn.Conv2d(128, 128, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "        )        \n",
        "        self.fc = nn.Sequential(\n",
        "            # reshape input, 128 -> 1\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, y=None):\n",
        "        y_ = self.conv(x)\n",
        "        y_ = y_.view(y_.size(0), -1)\n",
        "        y_ = self.fc(y_)\n",
        "        return y_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "848iFfMtZskv"
      },
      "source": [
        "# Recordar que a diferencia de MNIST ahora se está trabajando con imágenes a color por lo que cambian las dimensiones\n",
        "transform = transforms.Compose([transforms.Resize((IMAGE_DIM[0],IMAGE_DIM[1])),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5, 0.5, 0.5),\n",
        "                                std=(0.5, 0.5, 0.5))\n",
        "                               ]\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}