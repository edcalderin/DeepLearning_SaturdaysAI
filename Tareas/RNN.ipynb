{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tarea.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edcalderin/DeepLearning_SaturdaysAI/blob/master/Tareas/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBpApAN7husX"
      },
      "source": [
        "# Tarea: Recurrent Neural Networks\n",
        "### Grupo: XXXXX\n",
        "Integrantes:\n",
        "<br>\n",
        "* Integrante 1 \n",
        "* Integrante 2\n",
        "* Integrante 3\n",
        "* Integrante 4\n",
        "<br>\n",
        "\n",
        "Indicaciones:\n",
        "<rb>\n",
        "* Debe realizar la siguiente tarea hasta el miercoles 16 de junio, 23:59 UTC - 4\n",
        "* Debe hacer una copia de este notebook para poder editar el código.\n",
        "* Debe poner el código faltante en las celdas que correspondan.\n",
        "* Una vez finalizado el trabajo debe subir el link de su notebook (con permisos de lector) en la sección de \"Tareas\" del Módulo 3: Recurrent Neural Networks en Eduflow.\n",
        "\n",
        "En la parte práctica de la clase, vimos cómo entrenar una red neuronal recurrente (RNN) para la tarea del análisis del sentimiento. Sin embargo, los resultados en el test set no fueron nada buenos. En este ejercicio, haremos unos cuantos cambios para crear un modelo que nos dé una precisión de más del 80%:\n",
        "\n",
        "\n",
        "\n",
        "*   Cambiar el RNN por un **LSTM bidireccional**\n",
        "*   Utilizar **pre-trained word embeddings** españoles\n",
        "*   Regularización\n",
        "*   Un optimizer distinto\n",
        "*   Procesaremos solo los elementos que no son *padding* (**packed padded sequences**)\n",
        "\n",
        "Para utilizar los embeddings, hay que bajarse el fichero de https://www.kaggle.com/rtatman/pretrained-word-vectors-for-spanish tal y como vimos en la parte práctica. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Psg30h58inUS",
        "outputId": "771ade1b-8476-4c36-e446-27bf68e36247"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3E6CU_2kD0G"
      },
      "source": [
        "# Bajarse el tokenizer español de SpaCy\n",
        "\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHC7WiZDkTNV"
      },
      "source": [
        "Recordad que después de bajarse el tokenizer, para que funcione correctamente hay que reanudar el runtime.\n",
        "\n",
        "*Runtime -> Restart runtime*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3hDuvNUkxoB"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "Vamos a inizializar el dataset en torchtext tal y como hicimos en las prácticas. Sin embargo, vamos a añador un parámetro extra en *data.Field* de TEXT llamado *include_lengths=True*. Para poder procesar los elementos que no son padding, necesitamos saber la longitud de cada texto en el dataset.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMzA-C_Akjs1"
      },
      "source": [
        "# Inicializar torchtext dataset\n",
        "\n",
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = ## SU CÓDIGO AQUÍ ##\n",
        "\n",
        "SENTIMENT = ## SU CÓDIGO AQUÍ ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsU-gTxImv-F"
      },
      "source": [
        "# Indicar a torchtext qué campos corresponden a los distintos elementos del json\n",
        "\n",
        "fields = ## SU CÓDIGO AQUÍ ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCrVaeTSm3AS"
      },
      "source": [
        "Ahora vamos a leer el corpus. Vamos a utilizar los tres ficheros (**train.json**, **valid.json** y **test.json**) que vimos en la parte práctica. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtj19CD3nB6j"
      },
      "source": [
        "# Leer corpus\n",
        "\n",
        "PATH = 'drive/MyDrive/Saturdays.AI/data_sentimiento'\n",
        "\n",
        "train_data, valid_data, test_data = ## SU CÓDIGO AQUÍ ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHdyaDU6nakA"
      },
      "source": [
        "Como vamos a utilizar *pre-trained embeddings*, tenemos que añadirlos cuando construimos el vocabulario. Para inicializar el vocabulario en los pre-trained embeddings a 0, añadimos el parámetro *unk_init*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4pTybBTnsnv"
      },
      "source": [
        "# Leer embeddings, este proceso puede tardar unos segundos\n",
        "\n",
        "import torchtext.vocab as vocab\n",
        "\n",
        "FILE_NAME = 'SBW-vectors-300-min5.txt'\n",
        "PATH = ## SU PATH AQUÍ ##\n",
        "\n",
        "spanish_embeddings = vocab.Vectors(FILE_NAME, cache=PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4LmQnrboR_E"
      },
      "source": [
        "# Constuir vocabulario \n",
        "\n",
        "MAX_VOCAB_SIZE = 4000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = spanish_embeddings, \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "SENTIMENT.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o65_gXLvo9tZ"
      },
      "source": [
        "# Preparar train, valid y test iterators para entrenar el modelo\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = ## SU CÓDIGO AQUÍ ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJFsBheKqIAk",
        "outputId": "58232dae-c514-43f0-e0a3-58196994152d"
      },
      "source": [
        "# Para ver la dimensión de los pre-trained embeddings\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4002, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y_yoI2ipNLm"
      },
      "source": [
        "# Modelo\n",
        "\n",
        "Construimos el modelo que entrenaremos y evaluaremos. En esta tarea utilizamos un **LSTM bidireccional**. \n",
        "\n",
        "La *embedding* layer tendrá un parámetro extra, ***padding_idx=pad_idx***, que indica el índice del token *pad* para que el model no lo procese.\n",
        "\n",
        "La *rnn* layer será ahora de tipo **nn.LSTM** con los parámetros siguientes:\n",
        "\n",
        "\n",
        "*   **embedding_dim**: dimensión de los pre-trained embeddings\n",
        "*   **hidden_dim**: dimensión de la hidden layer\n",
        "*   **num_layer**: número de layers\n",
        "*   **bidirectional**: queremos un LSTM bidireccional \n",
        "*   **dropout**: el dropout para regularizar la red neuronal\n",
        "\n",
        "Luego añadimos una **layer linear** y *dropout*. La dimensión de la hidden layer que pasamos por la linear layer es el **doble** porque concatenamos las dos hidden layers con distintas direcciones. \n",
        "\n",
        "También vamos a definir el paso forward. Atención que utilizamos *dropout* y *packed_padded_sequence*. Al final concatenamos las dos hidden layers del Bidirectional LSTM. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKvi23SWpOz2"
      },
      "source": [
        "# Construir modelo\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding = ## SU CÓDIGO AQUÍ ##\n",
        "\n",
        "    self.rnn = ## SU CÓDIGO AQUÍ ##\n",
        "    \n",
        "    self.fc = ## SU CÓDIGO AQUÍ ##\n",
        "\n",
        "    self.dropout = ## SU CÓDIGO AQUÍ ##\n",
        "\n",
        "    # Forward pass\n",
        "  \n",
        "  def forward(self, text, text_lengths):\n",
        "\n",
        "    embedded = self.dropout(self.embedding(text))\n",
        "\n",
        "    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))\n",
        "    \n",
        "    packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "\n",
        "    output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "    hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
        "\n",
        "    return self.fc(hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVQzeOelptLt"
      },
      "source": [
        "# Definimos parámetros, algunos (como hidden_dim o n_layers) los podéis cambiar y experimentar\n",
        "\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 450\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 3\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "# Inicializamos el modelo con todos los parámetros\n",
        "\n",
        "## SU CÓDIGO AQUÍ ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdtRhTP0qTvE"
      },
      "source": [
        "# Para ver el número de parámetros que entrenaremos en la red neuronal\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'El modelo tiene {count_parameters(model):,} parámetros')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZenuM4Lvfv4"
      },
      "source": [
        "Finalmente, copiamos los pre-trained word embeddings y los metemos en la *embedding layer*. Luego reemplazamos los valores iniciales de la *embedding layer* con los pre-trained embeddings. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VURTTdmIvfSE"
      },
      "source": [
        "# Copiamos pre-trained embeddings\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "# Inicializamos embedding layer\n",
        "\n",
        "model.embedding.weight.data.copy_(TEXT.vocab.vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNqeZQg7wZP0"
      },
      "source": [
        "# Entrenar \n",
        "\n",
        "Vamos a entrenar el modelo. Empezamos definiendo el *optimizer*. Esta vez vamos a utilizar **Adam**. Utilizamos la misma loss function que vimos en la parte práctica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8oljxiTwlPw"
      },
      "source": [
        "# Optimizer\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "optimizer = ## SU CÓDIGO AQUÍ ##\n",
        "\n",
        "# loss function\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fePKaTFjxE9A"
      },
      "source": [
        "# Modelo y loss function en GPU\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kYTWxvNxFjz"
      },
      "source": [
        "# función para calcular accuracy \n",
        "\n",
        "def binary_accuracy(preds, y):\n",
        "  rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "  correct = (rounded_preds == y).float()\n",
        "  acc = correct.sum() / len(correct)\n",
        "  return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bYQQe9SxxuN"
      },
      "source": [
        "Definimos la función para entrenar el modelo. Como que hemos incluido el parámetro *include_lengths=True*, en este caso *batch.t* es una tupla con el primer elemento una tensor de números y el segundo elemento la longitud de cada texto. Con lo cual, antes de pasar *batch.t*, tendremos que separar estos dos elementos:\n",
        "\n",
        "**text, text_lengths = batch.t**\n",
        "\n",
        "Y pasar las dos variables (*text* y *text_lengths*) al modelo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sheb8LRpxS38"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "  ## SU CÓDIGO AQUÍ ##\n",
        "  \n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJVqDLB5zGGI"
      },
      "source": [
        "Para definir la función que evalúa el modelo, recordar que es muy similar a *train*, con alguna diferencia (ver ejercicio práctico). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPCVqfAezQqd"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    ## SU CÓDIGO AQUÍ ##\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuL_zMoezRZH"
      },
      "source": [
        "# Función para saber el tiempo que se tarda para entrenar cada epoch\n",
        "\n",
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtbC-1rNzup2"
      },
      "source": [
        "Vamos a entrenar tal y como lo hicimos en el ejercicio práctico. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyA-VWG6zjRv"
      },
      "source": [
        "# Entrenamos\n",
        "\n",
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    ## SU CÓDIGO AQUÍ ##\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHo87hbt12Sw"
      },
      "source": [
        "# Test\n",
        "\n",
        "Vamos a ver la precisión del modelo en el test data. Deberías obtener una accuracy alrededor del 80%!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw0XemwN2BHm"
      },
      "source": [
        "# Resultados en el test set\n",
        "\n",
        "MODEL_NAME = ## SU NOMBRE AQUÍ ##\n",
        "\n",
        "model.load_state_dict(torch.load(MODEL_NAME))\n",
        "\n",
        "test_loss, test_acc = ## SU CÓDIGO AQUÍ ##\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE-eQlla2Vib"
      },
      "source": [
        "Si quieres ver cómo funciona el modelo con tus propios comentarios positivos o negativos, podemos crear una función para hacer predicciones.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnbmWk_d2nmO"
      },
      "source": [
        "# Cargar el tokenizer de SpaCy\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "\n",
        "# Función para predecir sentimiento \n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "    # modelo en modo evaluación\n",
        "    model.eval()\n",
        "    # tokenizar texto\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    # transformar palabras en sus índices del vocabulario\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    # convertir lista de índices en tensor\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    # añadir una dimensión para batch\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    # convertir length en un tensor\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # predecir, utilizando sigmoid para obtener un número entre 0 y 1\n",
        "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
        "    if prediction.item() >= 0.5:\n",
        "      return \"negativo\"\n",
        "    else:\n",
        "      return \"positivo\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzPGDs6p36Ze"
      },
      "source": [
        "# Podéis probar con el texto que queráis. \n",
        "\n",
        "TEXTO = \"Servicio excelente!\"\n",
        "\n",
        "predict_sentiment(model, TEXTO)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}